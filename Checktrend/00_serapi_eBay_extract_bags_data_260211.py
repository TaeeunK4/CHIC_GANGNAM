"""
eBay ëª…í’ˆ ë°± íŒë§¤ ì™„ë£Œ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (Serapi í™œìš©)
ìˆ˜ì§‘ ë°ì´í„°: íŒë§¤ì¼ì, ê°€ê²©, ìƒí’ˆì œëª©, ìƒ‰ìƒ, ì¢…ë¥˜
"""

import os
import pandas as pd
from serpapi import GoogleSearch
from datetime import datetime
import time
import re

# Serapi API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
API_KEY = os.getenv('SERPAPI_KEY', 'd266baa616db5d4f6a54863181fb1578c4eb6e2aa2888610f77155199b31b36c')

# ëª…í’ˆ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ (ë¸Œëœë“œ íŒŒì‹±ìš©)
LUXURY_BRANDS = [
    'Louis Vuitton',
    'Chanel',
    'Hermes',
    'HermÃ¨s',
    'Gucci',
    'Prada',
    'Dior',
    'Fendi',
    'Celine',
    'Balenciaga',
    'Bottega Veneta',
    'Saint Laurent',
    'Yves Saint Laurent',
    'YSL',
    'Givenchy',
    'Valentino',
    'Burberry',
    'Michael Kors',
    'Coach',
    'Kate Spade',
    'Marc Jacobs',
    'Versace',
    'Dolce & Gabbana',
    'Dolce Gabbana',
    'Salvatore Ferragamo',
    'Ferragamo',
    'Mulberry',
    'Alexander McQueen',
    'Stella McCartney',
    'Loewe',
    'Goyard'
]

# í†µí•© ê²€ìƒ‰ í‚¤ì›Œë“œ (ì „ì²´ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ìš©)
SEARCH_KEYWORDS = [
    'luxury designer bag authentic',
    'designer handbag authentic',
    'luxury handbag'
]

def extract_brand_from_title(title):
    """ìƒí’ˆ ì œëª©ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ"""
    title_lower = title.lower()

    # ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ ê²ƒë¶€í„° ë§¤ì¹­ - 'Louis Vuitton'ì´ 'Louis'ë³´ë‹¤ ë¨¼ì €)
    sorted_brands = sorted(LUXURY_BRANDS, key=len, reverse=True)

    for brand in sorted_brands:
        if brand.lower() in title_lower:
            # ì›ë³¸ ë¸Œëœë“œëª… ì¤‘ ê°€ì¥ ëŒ€í‘œì ì¸ ê²ƒìœ¼ë¡œ í†µì¼
            if brand.lower() in ['ysl', 'yves saint laurent']:
                return 'Saint Laurent'
            elif brand.lower() in ['hermÃ¨s']:
                return 'Hermes'
            elif brand.lower() in ['dolce gabbana', 'dolce & gabbana']:
                return 'Dolce & Gabbana'
            elif brand.lower() in ['ferragamo']:
                return 'Salvatore Ferragamo'
            else:
                return brand

    return 'Other'

def extract_color_from_title(title):
    """ìƒí’ˆ ì œëª©ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ"""
    colors = ['black', 'white', 'red', 'blue', 'brown', 'pink', 'green',
              'beige', 'gray', 'grey', 'navy', 'tan', 'gold', 'silver',
              'yellow', 'purple', 'orange', 'cream', 'burgundy']

    title_lower = title.lower()
    for color in colors:
        if color in title_lower:
            return color.capitalize()
    return 'Unknown'

def extract_bag_type_from_title(title):
    """ìƒí’ˆ ì œëª©ì—ì„œ ê°€ë°© ì¢…ë¥˜ ì¶”ì¶œ"""
    bag_types = ['tote', 'shoulder', 'crossbody', 'clutch', 'backpack',
                 'hobo', 'satchel', 'wallet', 'handbag', 'purse',
                 'messenger', 'bucket', 'bowling']

    title_lower = title.lower()
    for bag_type in bag_types:
        if bag_type in title_lower:
            return bag_type.capitalize()
    return 'Handbag'

def fetch_ebay_sold_bags(keyword, max_pages=20):
    """
    í†µí•© ê²€ìƒ‰ìœ¼ë¡œ íŒë§¤ ì™„ë£Œëœ ëª…í’ˆ ë°± ë°ì´í„° ìˆ˜ì§‘

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ 20í˜ì´ì§€)

    Returns:
        list: íŒë§¤ ì™„ë£Œ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
    """
    all_items = []

    for page in range(max_pages):
        print(f"Fetching '{keyword}' - Page {page + 1}/{max_pages}...")

        params = {
            "api_key": API_KEY,
            "engine": "ebay",
            "ebay_domain": "ebay.com",
            "_nkw": keyword,  # ê²€ìƒ‰ í‚¤ì›Œë“œ
            "LH_Sold": "1",  # íŒë§¤ ì™„ë£Œ í•„í„°
            "LH_Complete": "1",  # ê±°ë˜ ì™„ë£Œ í•„í„°
            "_pgn": page + 1,  # í˜ì´ì§€ ë²ˆí˜¸
            "_ipg": "100"  # í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ (ìµœëŒ€ 100)
        }

        try:
            search = GoogleSearch(params)
            results = search.get_dict()

            # ì—ëŸ¬ ì²´í¬
            if "error" in results:
                print(f"âŒ API Error: {results['error']}")
                break

            if "organic_results" not in results:
                if page == 0:
                    print(f"âš ï¸ No results found for '{keyword}'")
                break

            items = results.get("organic_results", [])

            if not items:
                break

            for item in items:
                # ë°ì´í„° ì¶”ì¶œ
                try:
                    # ê°€ê²© ì¶”ì¶œ
                    price_raw = 'N/A'
                    if isinstance(item.get('price'), dict):
                        price_raw = item.get('price', {}).get('raw', 'N/A')
                    elif isinstance(item.get('price'), str):
                        price_raw = item.get('price')

                    # íŒë§¤ ë‚ ì§œ ì¶”ì¶œ (extensionsì—ì„œ)
                    sold_date = 'N/A'
                    extensions = item.get('extensions', [])
                    if extensions:
                        for ext in extensions:
                            if 'Sold' in ext or 'sold' in ext:
                                sold_date = ext
                                break

                    title = item.get('title', '')

                    product_data = {
                        'brand': extract_brand_from_title(title),
                        'title': title,
                        'price': price_raw,
                        'sold_date': sold_date,
                        'condition': item.get('condition', 'N/A'),
                        'shipping': item.get('shipping', 'N/A'),
                        'location': item.get('location', 'N/A'),
                        'link': item.get('link', ''),
                        'color': extract_color_from_title(title),
                        'bag_type': extract_bag_type_from_title(title)
                    }
                    all_items.append(product_data)
                except Exception as e:
                    print(f"Error parsing item: {e}")
                    continue

            # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
            time.sleep(1)

        except Exception as e:
            print(f"Error fetching page {page + 1}: {e}")
            break

    return all_items

def clean_price(price_str):
    """ê°€ê²© ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜"""
    if isinstance(price_str, str):
        # $ ê¸°í˜¸ì™€ ì‰¼í‘œ ì œê±°
        price_clean = re.sub(r'[$,]', '', price_str)
        try:
            return float(price_clean)
        except:
            return None
    return price_str

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("eBay ëª…í’ˆ ë°± íŒë§¤ ì™„ë£Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ì „ì²´ ì‹œì¥ ë¶„ì„)")
    print("=" * 60)

    all_data = []

    # í†µí•© ê²€ìƒ‰ìœ¼ë¡œ ì „ì²´ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
    for idx, keyword in enumerate(SEARCH_KEYWORDS, 1):
        print(f"\nğŸ” Collecting data for: '{keyword}' ({idx}/{len(SEARCH_KEYWORDS)})")
        keyword_data = fetch_ebay_sold_bags(keyword, max_pages=20)
        all_data.extend(keyword_data)
        print(f"âœ“ Collected {len(keyword_data)} items for '{keyword}'")

    # DataFrame ìƒì„±
    df = pd.DataFrame(all_data)

    if df.empty:
        print("\nâš ï¸ No data collected. Please check your API key and internet connection.")
        return

    # ì¤‘ë³µ ì œê±° (ê°™ì€ ìƒí’ˆì´ ì—¬ëŸ¬ ê²€ìƒ‰ì–´ì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
    print(f"\nğŸ“Š Total items before deduplication: {len(df)}")
    df = df.drop_duplicates(subset=['link'], keep='first')
    print(f"ğŸ“Š Total items after deduplication: {len(df)}")

    # ê°€ê²© ì •ë¦¬
    df['price_cleaned'] = df['price'].apply(clean_price)

    # ìµœì¢… ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ë³€ê²½
    final_df = df[[
        'brand',
        'title',
        'price',
        'price_cleaned',
        'sold_date',
        'color',
        'bag_type',
        'condition',
        'shipping',
        'location',
        'link'
    ]].copy()

    # ì»¬ëŸ¼ëª… ë³€ê²½ (ì˜ì–´ë¡œ)
    final_df.columns = [
        'Brand',
        'Product_Title',
        'Price_Original',
        'Price_USD',
        'Sold_Date',
        'Color',
        'Bag_Type',
        'Condition',
        'Shipping',
        'Location',
        'Product_Link'
    ]

    # ê²°ê³¼ ì €ì¥
    output_file = f'ebay_luxury_bags_sold_{datetime.now().strftime("%Y%m%d")}.csv'
    final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

    print("\n" + "=" * 60)
    print(f"âœ… Data collection completed!")
    print(f"ğŸ“Š Total items collected: {len(final_df)}")
    print(f"ğŸ” Search keywords used: {len(SEARCH_KEYWORDS)}")
    print(f"ğŸ’¾ Saved to: {output_file}")
    print("=" * 60)

    # ìƒì„¸ í†µê³„ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ì „ì²´ ì‹œì¥ íŒë§¤ëŸ‰ ë¶„ì„")
    print("=" * 60)

    # ë¸Œëœë“œë³„ íŒë§¤ëŸ‰ (ìƒìœ„ 15ê°œ)
    print("\nğŸ·ï¸ ë¸Œëœë“œë³„ íŒë§¤ëŸ‰ (Top 15):")
    brand_counts = final_df['Brand'].value_counts().head(15)
    for idx, (brand, count) in enumerate(brand_counts.items(), 1):
        percentage = (count / len(final_df)) * 100
        print(f"   {idx:2d}. {brand:20s} - {count:4d}ê°œ ({percentage:5.1f}%)")

    # ìƒ‰ìƒë³„ íŒë§¤ëŸ‰
    print("\nğŸ¨ ìƒ‰ìƒë³„ íŒë§¤ëŸ‰:")
    color_counts = final_df['Color'].value_counts().head(10)
    for idx, (color, count) in enumerate(color_counts.items(), 1):
        percentage = (count / len(final_df)) * 100
        print(f"   {idx:2d}. {color:15s} - {count:4d}ê°œ ({percentage:5.1f}%)")

    # ê°€ë°© ì¢…ë¥˜ë³„ íŒë§¤ëŸ‰
    print("\nğŸ‘œ ê°€ë°© ì¢…ë¥˜ë³„ íŒë§¤ëŸ‰:")
    bag_type_counts = final_df['Bag_Type'].value_counts().head(10)
    for idx, (bag_type, count) in enumerate(bag_type_counts.items(), 1):
        percentage = (count / len(final_df)) * 100
        print(f"   {idx:2d}. {bag_type:15s} - {count:4d}ê°œ ({percentage:5.1f}%)")

    # ê°€ê²© í†µê³„
    print("\nğŸ’° ê°€ê²© í†µê³„:")
    if final_df['Price_USD'].notna().sum() > 0:
        print(f"   - í‰ê·  ê°€ê²©: ${final_df['Price_USD'].mean():.2f}")
        print(f"   - ì¤‘ê°„ ê°€ê²©: ${final_df['Price_USD'].median():.2f}")
        print(f"   - ìµœì € ê°€ê²©: ${final_df['Price_USD'].min():.2f}")
        print(f"   - ìµœê³  ê°€ê²©: ${final_df['Price_USD'].max():.2f}")

    # ë¸Œëœë“œë³„ í‰ê·  ê°€ê²© (ìƒìœ„ 10ê°œ ë¸Œëœë“œ)
    print("\nğŸ’ ë¸Œëœë“œë³„ í‰ê·  ê°€ê²© (Top 10):")
    top_brands = final_df['Brand'].value_counts().head(10).index
    brand_avg_price = final_df[final_df['Brand'].isin(top_brands)].groupby('Brand')['Price_USD'].mean().sort_values(ascending=False)
    for idx, (brand, avg_price) in enumerate(brand_avg_price.items(), 1):
        if pd.notna(avg_price):
            print(f"   {idx:2d}. {brand:20s} - ${avg_price:,.2f}")

    return final_df

if __name__ == "__main__":
    # API í‚¤ í™•ì¸
    if not API_KEY or API_KEY == 'YOUR_API_KEY_HERE':
        print("âš ï¸ Please set your SERPAPI_KEY!")
        print("Option 1: Set environment variable: export SERPAPI_KEY='your_key'")
        print("Option 2: Replace 'YOUR_API_KEY_HERE' in the code with your actual API key")
        print("\nGet your free API key at: https://serpapi.com/")
    else:
        df = main()